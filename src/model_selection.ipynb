{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage.io as scio\n",
    "from ipywidgets import interact, fixed, IntSlider, FloatSlider\n",
    "import seaborn as sb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the right network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_helpers as dh\n",
    "batchsize = 64\n",
    "# These shapes are considered after cropping\n",
    "mri_shape = [batchsize, 160, 160, 3]\n",
    "seg_shape = [batchsize, 160, 160, 1]\n",
    "def load_dataset():\n",
    "    validation_dataset_name = 'brats2015-Train-all_validation_crop_mri'\n",
    "    validation_dataset = dh.load_dataset('../datasets/brats2015-Train-all_validation_crop_mri',\n",
    "                                     mri_type=['MR_T1c', 'MR_T2', 'MR_Flair'],\n",
    "                                     center_crop=mri_shape[1:],\n",
    "                                     batch_size=batchsize,\n",
    "                                     prefetch_buffer=1,\n",
    "                                     clip_labels_to=1.0,\n",
    "                                     infinite = False,\n",
    "                                     interleave=1,\n",
    "                                     shuffle=False\n",
    "                                )\n",
    "    return validation_dataset\n",
    "\n",
    "\n",
    "def load_network(run_name, config):\n",
    "    from SegAN_IO import SegAN_IO\n",
    "    net = SegAN_IO(mri_shape, seg_shape, config=config, run_name=run_name)\n",
    "    return net\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_validation(run_name, checkpoint):\n",
    "    '''\n",
    "    :param input_mri: NDArray of shape [batch_size, H, W, channels]\n",
    "    '''\n",
    "\n",
    "    result_list = list()\n",
    "    \n",
    "    # Creating the iterator\n",
    "    tf.reset_default_graph()\n",
    "    validation_dataset = load_dataset()\n",
    "    iterator = validation_dataset.make_one_shot_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        net = load_network(run_name, config)\n",
    "        # Load (build) the network from the checkpoint\n",
    "        net.build_network(next_batch['mri'], next_batch['seg'], session=sess, load_checkpoint=checkpoint)\n",
    "        # Running evaluations on the entire dataset\n",
    "        while True:\n",
    "            try:\n",
    "                results = sess.run({'prediction': net.layers['S']['out'], 'input': net.layers['in']['mri'], 'ground_truth': net.layers['in']['seg']}, feed_dict={net.layers['in']['training']: False})  \n",
    "                result_list.append(results)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "    return result_list\n",
    "    \n",
    "    \n",
    "    \n",
    "def evaluate_all_checkpoints(run_name, checkpoint_folder, mri_shape, seg_shape):\n",
    "    import dataset_helpers as dh\n",
    "    import pandas as pd\n",
    "           \n",
    "    all_checkpoints = tf.train.get_checkpoint_state(checkpoint_folder).all_model_checkpoint_paths\n",
    "    result_list = list()\n",
    "    for checkpoint in all_checkpoints:\n",
    "        # Creating the iterator\n",
    "        tf.reset_default_graph()\n",
    "        iterator = validation_dataset.make_one_shot_iterator()\n",
    "        next_batch = iterator.get_next()\n",
    "        \n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            net = load_network(run_name, config)\n",
    "            # Load (build) the network from the checkpoint\n",
    "            net.build_network(next_batch['mri'], next_batch['seg'], session=sess, load_checkpoint=checkpoint)\n",
    "            # Running evaluations on the entire dataset\n",
    "            while True:\n",
    "                try:\n",
    "                    results = sess.run(net.layers['eval'], feed_dict={net.layers['in']['training']: False})\n",
    "                    results['checkpoint'] = checkpoint\n",
    "                    result_list.append(results)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "                    \n",
    "    # Make a DataFrame with all the results\n",
    "    pd_eval = pd.DataFrame(result_list)\n",
    "    # Save to CSV\n",
    "    pd_eval.to_csv('eval_{}.csv'.format(run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stats for every batch and save them in a csv file (takes about an hour)\n",
    "#evaluations = evaluate_all_checkpoints('loss_fixed_26_feb', mri_shape=[32, 240, 240, 1], seg_shape=[32, 240, 240, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ev = pd.read_csv('eval_loss_fixed_26_feb.csv', index_col = 0)\n",
    "ev[\"batch_n\"] =ev.groupby(\"checkpoint\").cumcount() # Create a column for the batch enumeration\n",
    "ev = ev.set_index([\"checkpoint\", \"batch_n\"]) # Set the new indices\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which metrics make sense to consider by cheching the global stability\n",
    "ev.var()\n",
    "# 26 feb run showed that the metrics with most variance were sensitivity (2%), dice_score (1.3%), precision (1.2%). Balanced accuracy was at (0.5%) and others were mostly stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "evstats = ev.groupby(level=\"checkpoint\").agg(['mean', 'var'])\n",
    "top_models = list()\n",
    "for m in [\"dice_score\", \"sensitivity\", \"precision\", \"balanced_accuracy\"]:\n",
    "    top = evstats[m].nlargest(1, \"mean\")\n",
    "    print(\"Best {} model: {}\".format(m, top.index[0]))\n",
    "    top_models.append(top.index[0])\n",
    "evstats.loc[top_models,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a version for plotting (Not actually feasible for too many checkpoints)\n",
    "evp = ev.loc[top_models,:].stack().reset_index().rename(columns={'level_2':'metric', 0:'value'})\n",
    "sb.catplot(x=\"value\", y=\"checkpoint\", col=\"metric\", col_wrap=2, kind=\"box\", data=evp, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best checkpoint\n",
    "according to the validation set dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best step is 53500 with a dice score of 0.8258382678031921\n"
     ]
    }
   ],
   "source": [
    "dicescore = pd.read_csv('run_logs/18-apr-run_test-tag-avg_dice_score.csv')\n",
    "max_dice = dicescore.Value.max()\n",
    "best_step = int(dicescore.iloc[dicescore.Value.idxmax()].Step)\n",
    "print(\"Best step is {} with a dice score of {}\".format(best_step, max_dice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some predictions from validation set\n",
    "Load one checkpoint and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/SegAN/SeganIO_18Apr_model/model.ckpt-51500\n",
      "Loaded model from ../models/SegAN/SeganIO_18Apr_model/ at global step 51500\n"
     ]
    }
   ],
   "source": [
    "model = \"../models/SegAN/SeganIO_18Apr_model/model.ckpt-51500\"\n",
    "results = predict_from_validation(run_name='SeganIO_18Apr', checkpoint=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a2252b18e84c3b824e1ea9cbb6dfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='batch_n', max=55), IntSlider(value=0, description='samplâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_results(results, batch_n, sample_n, gt_alpha, pred_alpha):\n",
    "    input_sample = results[batch_n]['input'][sample_n, :,:,0]\n",
    "    prediction = results[batch_n]['prediction'][sample_n, :,:,0]\n",
    "    ground_truth = results[batch_n]['ground_truth'][sample_n, :,:,0]\n",
    "    \n",
    "    blank_channel = np.zeros([input_sample.shape[0], input_sample.shape[1]])\n",
    "    \n",
    "    # Make prediction and ground truth RGBA\n",
    "    prediction = np.expand_dims(prediction, axis=-1)\n",
    "    # Create a greyscale image with alpha channel\n",
    "    prediction = prediction.repeat(4, axis=-1)\n",
    "    # Make the prediction red\n",
    "    prediction[:,:,1] = blank_channel\n",
    "    prediction[:,:,2] = blank_channel\n",
    "    # Same for the ground truth\n",
    "    ground_truth = np.expand_dims(ground_truth, axis=-1)\n",
    "    ground_truth = ground_truth.repeat(4, axis=-1)\n",
    "    ground_truth[:,:,0] = blank_channel\n",
    "    ground_truth[:,:,2] = blank_channel\n",
    "    \n",
    "    plt.figure(figsize=(8, 6), dpi=120)\n",
    "    plt.imshow(input_sample, cmap=\"binary_r\")\n",
    "    plt.imshow(ground_truth, alpha=gt_alpha, cmap=\"Reds_r\")\n",
    "    plt.imshow(prediction, alpha=pred_alpha, cmap=\"Greens\")\n",
    "    \n",
    "\n",
    "\n",
    "interact(visualize_results, results=fixed(results), batch_n=IntSlider(min=0,max=len(results)-1,step=1,value=0), sample_n=IntSlider(min=0,max=31,step=1,value=0), gt_alpha=FloatSlider(min=0,max=1,step=0.1,value=0), pred_alpha=FloatSlider(min=0,max=1,step=0.1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
