{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepMRI import DeepMRI\n",
    "import SegAN_IO_arch as seganio\n",
    "import dataset_helpers as dh\n",
    "from NegotiationTools import NegTools\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negtools = NegTools() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = 'models/'\n",
    "checkpoint_basename = 'best_dice_score_'\n",
    "output_labels = 1\n",
    "model_input_size = 160\n",
    "seed=1234567890\n",
    "\n",
    "dataset = {\n",
    "           'training':'brats2015_training_crop_mri',\n",
    "           'validation':'brats2015_validation_crop_mri',\n",
    "           'testing':'brats2015_testing_crop_mri'\n",
    "          }\n",
    "\n",
    "full_network = {'path': 'Segan_IO_TF2_brats_ALL', 'epoch': 1123, 'modalities': [\"MR_T1\", \"MR_T1c\", \"MR_T2\", \"MR_Flair\"]}\n",
    "\n",
    "single_modalities = \\\n",
    "    {\n",
    "    'MR_T1': {'path': 'Segan_IO_TF2_brats_on_T1', 'epoch': 861, 'modalities': [\"MR_T1\"], \"performance\":0.5304, \"weight\": 0.25},\n",
    "    'MR_T1c': {'path': 'Segan_IO_TF2_brats_on_T1c', 'epoch': 1011, 'modalities': [\"MR_T1c\"], \"performance\":0.5822, \"weight\": 0.25},\n",
    "    'MR_T2': {'path': 'Segan_IO_TF2_brats_on_T2', 'epoch': 182, 'modalities': [\"MR_T2\"], \"performance\":0.7439, \"weight\": 0.5},\n",
    "    'MR_Flair': {'path': 'Segan_IO_TF2_brats_on_FLAIR', 'epoch': 168, 'modalities': [\"MR_Flair\"], \"performance\":0.8040, \"weight\": 0.5}\n",
    "    }\n",
    "\n",
    "transfer_from_flair = \\\n",
    "    {\n",
    "    'MR_T1': {'path': 'Transfer_Brats_Flair_to_T1_freeze_all', 'epoch': 1122, 'modalities': [\"MR_T1\"], \"performance\":0.5701, \"weight\": 0.25},\n",
    "    'MR_T1c': {'path': 'Transfer_Brats_Flair_to_T1c_freeze_all', 'epoch': 751, 'modalities': [\"MR_T1c\"], \"performance\":0.5463, \"weight\": 0.25},\n",
    "    'MR_T2': {'path': 'Transfer_Brats_Flair_to_T2_freeze_all', 'epoch': 649, 'modalities': [\"MR_T2\"], \"performance\":0.7946, \"weight\": 0.5}\n",
    "    }\n",
    "\n",
    "test_data = dh.load_dataset(dataset['testing'],\n",
    "                    mri_type=full_network['modalities'],\n",
    "                    ground_truth_column_name='OT',\n",
    "                    clip_labels_to=output_labels,\n",
    "                    center_crop=[model_input_size, model_input_size, len(full_network['modalities'])],\n",
    "                    batch_size=64,\n",
    "                    prefetch_buffer=1,\n",
    "                    infinite=False,\n",
    "                    cache=False,\n",
    "                    shuffle=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats_ALL/best_dice_score_1123-51\n",
      "Resuming model from: models/Segan_IO_TF2_brats_ALL/best_dice_score_1123-51, next epoch: 1124\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats_on_T1/best_dice_score_861-45\n",
      "Resuming model from: models/Segan_IO_TF2_brats_on_T1/best_dice_score_861-45, next epoch: 862\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats_on_T1c/best_dice_score_1011-48\n",
      "Resuming model from: models/Segan_IO_TF2_brats_on_T1c/best_dice_score_1011-48, next epoch: 1012\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats_on_T2/best_dice_score_182-25\n",
      "Resuming model from: models/Segan_IO_TF2_brats_on_T2/best_dice_score_182-25, next epoch: 183\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats_on_FLAIR/best_dice_score_168-29\n",
      "Resuming model from: models/Segan_IO_TF2_brats_on_FLAIR/best_dice_score_168-29, next epoch: 169\n"
     ]
    }
   ],
   "source": [
    "# Loading Single Modality Models\n",
    "full_network['checkpoint'] = glob.glob(MODELS_PATH + full_network['path'] + '/' + checkpoint_basename + str(full_network['epoch']) + '*.index')[0].replace('.index', '')\n",
    "full_network['model'] = DeepMRI(batch_size=64, size=model_input_size, mri_channels=len(full_network['modalities']), output_labels=output_labels, model_name=full_network['path'])\n",
    "full_network['model'].build_model(load_model=full_network['checkpoint'], seed=1234567890, arch=seganio)\n",
    "full_network['model'].mri_types = full_network['modalities'] # workaround for using log_step without loading a dataset\n",
    "\n",
    "for modality in full_network['modalities']:\n",
    "    single_modalities[modality]['checkpoint'] = glob.glob(MODELS_PATH + single_modalities[modality]['path'] + '/' + checkpoint_basename + str(single_modalities[modality]['epoch']) + '*.index')[0].replace('.index', '')\n",
    "    single_modalities[modality]['model'] = DeepMRI(batch_size=64, size=model_input_size, mri_channels=len(single_modalities[modality]['modalities']), output_labels=output_labels, model_name=single_modalities[modality]['path'])\n",
    "    single_modalities[modality]['model'].build_model(load_model=single_modalities[modality]['checkpoint'], seed=1234567890, arch=seganio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    preds = full_network['model'].generator(row['mri']).numpy()\n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], preds)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2015_performances_all_modalities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "# Majority voting between single modality networks\n",
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    for m, modality in enumerate(full_network['modalities']):\n",
    "        if modality == 'MR_Flair':\n",
    "            continue\n",
    "        predictions.append(single_modalities[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    \n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'maximum').astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2015_majority_voting_performances_single_modalities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "# Majority voting between single modality networks\n",
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    weights = list()\n",
    "    for m, modality in enumerate(full_network['modalities']):\n",
    "#         if modality == 'MR_Flair':\n",
    "#             continue\n",
    "        predictions.append(single_modalities[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        weights.append(single_modalities[modality]['weight'])\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    weights = np.asarray(weights)\n",
    "    weights = weights/np.sum(weights)\n",
    "    \n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    weights = np.tile(weights[:, None, None, None], [1, proposals.shape[2], proposals.shape[3], 2])\n",
    "    \n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'maximum', weights=weights).astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2015_weighted_majority_voting_performances_single_modalities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Transfer_Brats_Flair_to_T1_freeze_all/best_dice_score_1122-84\n",
      "Resuming model from: models/Transfer_Brats_Flair_to_T1_freeze_all/best_dice_score_1122-84, next epoch: 1123\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Transfer_Brats_Flair_to_T1c_freeze_all/best_dice_score_751-56\n",
      "Resuming model from: models/Transfer_Brats_Flair_to_T1c_freeze_all/best_dice_score_751-56, next epoch: 752\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Transfer_Brats_Flair_to_T2_freeze_all/best_dice_score_649-59\n",
      "Resuming model from: models/Transfer_Brats_Flair_to_T2_freeze_all/best_dice_score_649-59, next epoch: 650\n"
     ]
    }
   ],
   "source": [
    "for modality in full_network['modalities']:\n",
    "    if modality == 'MR_Flair':\n",
    "        continue\n",
    "    transfer_from_flair[modality]['checkpoint'] = glob.glob(MODELS_PATH + transfer_from_flair[modality]['path'] + '/' + checkpoint_basename + str(transfer_from_flair[modality]['epoch']) + '*.index')[0].replace('.index', '')\n",
    "\n",
    "\n",
    "for modality in [m for m in full_network['modalities'] if m != 'MR_Flair']:\n",
    "    transfer_from_flair[modality]['checkpoint'] = glob.glob(MODELS_PATH + transfer_from_flair[modality]['path'] + '/' + checkpoint_basename + str(transfer_from_flair[modality]['epoch']) + '*.index')[0].replace('.index', '')\n",
    "    transfer_from_flair[modality]['model'] = DeepMRI(batch_size=64, size=model_input_size, mri_channels=len(transfer_from_flair[modality]['modalities']), output_labels=output_labels, model_name=transfer_from_flair[modality]['path'])\n",
    "    transfer_from_flair[modality]['model'].build_model(load_model=transfer_from_flair[modality]['checkpoint'], seed=1234567890, arch=seganio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    for m, modality in enumerate([m for m in full_network['modalities'] if m != 'MR_Flair']):\n",
    "        predictions.append(transfer_from_flair[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'treshold').astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2015_majority_voting_performances_transfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    weights = list()\n",
    "    for m, modality in enumerate([m for m in full_network['modalities'] if m != 'MR_Flair']):\n",
    "        predictions.append(transfer_from_flair[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        weights.append(transfer_from_flair[modality]['weight'])\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    weights = np.asarray(weights)\n",
    "    weights = weights/np.sum(weights)\n",
    "    \n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    weights = np.tile(weights[:, None, None, None], [1, proposals.shape[2], proposals.shape[3], 2])\n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'maximum', weights=weights).astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    \n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2015_weighted_majority_voting_performances_transfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
