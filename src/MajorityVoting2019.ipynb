{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepMRI import DeepMRI\n",
    "import SegAN_IO_arch as seganio\n",
    "import dataset_helpers as dh\n",
    "from NegotiationTools import NegTools\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negtools = NegTools() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = 'models/'\n",
    "checkpoint_basename = 'best_dice_score_0_'\n",
    "output_labels = 1\n",
    "model_input_size = 160\n",
    "seed=1234567890\n",
    "\n",
    "dataset = {\n",
    "           'training':'brats2019_training_crop_mri',\n",
    "           'validation':'brats2019_validation_crop_mri',\n",
    "           'testing':'brats2019_testing_crop_mri'\n",
    "          }\n",
    "\n",
    "full_network = {'path': 'Segan_IO_TF2_brats2019_ALL', 'epoch': 133, 'modalities': [\"t1\", \"t1ce\", \"t2\", \"flair\"]}\n",
    "\n",
    "single_modalities = \\\n",
    "    {\n",
    "    't1': {'path': 'Segan_IO_TF2_brats2019_T1', 'epoch': 124, 'modalities': [\"t1\"], \"performance\":0.54, \"weight\": 0.25},\n",
    "    't1ce': {'path': 'Segan_IO_TF2_brats2019_T1ce', 'epoch': 597, 'modalities': [\"t1ce\"], \"performance\":0.59, \"weight\": 0.25},\n",
    "    't2': {'path': 'Segan_IO_TF2_brats2019_T2', 'epoch': 136, 'modalities': [\"t2\"], \"performance\":0.67, \"weight\": 0.5},\n",
    "    'flair': {'path': 'Segan_IO_TF2_brats2019_FLAIR', 'epoch': 89, 'modalities': [\"flair\"], \"performance\":0.76, \"weight\": 0.5}\n",
    "    }\n",
    "\n",
    "transfer_from_flair = \\\n",
    "    {\n",
    "    't1': {'path': 'Transfer_Brats2019_Flair_to_t1', 'epoch': 144, 'modalities': [\"t1\"], \"performance\":0.5, \"weight\": 0.25}, \n",
    "    't1ce': {'path': 'Transfer_Brats2019_Flair_to_t1ce_freeze_all', 'epoch': 300, 'modalities': [\"t1ce\"], \"performance\":0.56, \"weight\": 0.25},\n",
    "    't2': {'path': 'Transfer_Brats2019_Flair_to_t2_freeze_all', 'epoch': 191, 'modalities': [\"t2\"], \"performance\":0.72, \"weight\": 0.5}\n",
    "    }\n",
    "\n",
    "test_data = dh.load_dataset(dataset['validation'],\n",
    "                    mri_type=full_network['modalities'],\n",
    "                    ground_truth_column_name='seg',\n",
    "                    clip_labels_to=output_labels,\n",
    "                    center_crop=[model_input_size, model_input_size, len(full_network['modalities'])],\n",
    "                    batch_size=64,\n",
    "                    prefetch_buffer=1,\n",
    "                    infinite=False,\n",
    "                    cache=False,\n",
    "                    shuffle=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats2019_ALL/best_dice_score_0_133-18\n",
      "Resuming model from: models/Segan_IO_TF2_brats2019_ALL/best_dice_score_0_133-18, next epoch: 134\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats2019_T1/best_dice_score_0_124-10\n",
      "Resuming model from: models/Segan_IO_TF2_brats2019_T1/best_dice_score_0_124-10, next epoch: 125\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats2019_T1ce/best_dice_score_0_597-17\n",
      "Resuming model from: models/Segan_IO_TF2_brats2019_T1ce/best_dice_score_0_597-17, next epoch: 598\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats2019_T2/best_dice_score_0_136-11\n",
      "Resuming model from: models/Segan_IO_TF2_brats2019_T2/best_dice_score_0_136-11, next epoch: 137\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Segan_IO_TF2_brats2019_FLAIR/best_dice_score_0_89-10\n",
      "Resuming model from: models/Segan_IO_TF2_brats2019_FLAIR/best_dice_score_0_89-10, next epoch: 90\n"
     ]
    }
   ],
   "source": [
    "# Loading Single Modality Models\n",
    "full_network['checkpoint'] = glob.glob(MODELS_PATH + full_network['path'] + '/' + checkpoint_basename + str(full_network['epoch']) + '*.index')[0].replace('.index', '')\n",
    "full_network['model'] = DeepMRI(batch_size=64, size=model_input_size, mri_channels=len(full_network['modalities']), output_labels=output_labels, model_name=full_network['path'])\n",
    "full_network['model'].build_model(load_model=full_network['checkpoint'], seed=1234567890, arch=seganio)\n",
    "full_network['model'].mri_types = full_network['modalities'] # workaround for using log_step without loading a dataset\n",
    "\n",
    "for modality in full_network['modalities']:\n",
    "    single_modalities[modality]['checkpoint'] = glob.glob(MODELS_PATH + single_modalities[modality]['path'] + '/' + checkpoint_basename + str(single_modalities[modality]['epoch']) + '*.index')[0].replace('.index', '')\n",
    "    single_modalities[modality]['model'] = DeepMRI(batch_size=64, size=model_input_size, mri_channels=len(single_modalities[modality]['modalities']), output_labels=output_labels, model_name=single_modalities[modality]['path'])\n",
    "    single_modalities[modality]['model'].build_model(load_model=single_modalities[modality]['checkpoint'], seed=1234567890, arch=seganio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "# All modality network\n",
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    preds = full_network['model'].generator(row['mri']).numpy()\n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], preds)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2019_performances_all_modalities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "# Majority voting between single modality networks\n",
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    for m, modality in enumerate(full_network['modalities']):\n",
    "        if modality == 'flair':\n",
    "            continue\n",
    "        predictions.append(single_modalities[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'treshold').astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2019_majority_voting_performances_single_modalities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "# Weighted Majority voting between single modality networks\n",
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    weights = list()\n",
    "    for m, modality in enumerate(full_network['modalities']):\n",
    "#         if modality == 'flair':\n",
    "#             continue\n",
    "        predictions.append(single_modalities[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        weights.append(single_modalities[modality]['weight'])\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    weights = np.asarray(weights)\n",
    "    weights = weights/np.sum(weights)\n",
    "    \n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    weights = np.tile(weights[:, None, None, None], [1, proposals.shape[2], proposals.shape[3], 2])\n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'maximum', weights=weights).astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    \n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2019_weighted_majority_voting_performances_single_modalities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Transfer_Brats2019_Flair_to_t1/best_dice_score_0_144-25\n",
      "Resuming model from: models/Transfer_Brats2019_Flair_to_t1/best_dice_score_0_144-25, next epoch: 145\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Transfer_Brats2019_Flair_to_t1ce_freeze_all/best_dice_score_0_300-25\n",
      "Resuming model from: models/Transfer_Brats2019_Flair_to_t1ce_freeze_all/best_dice_score_0_300-25, next epoch: 301\n",
      "Using architecture: SegAN_IO_arch\n",
      "Loading models/Transfer_Brats2019_Flair_to_t2_freeze_all/best_dice_score_0_191-19\n",
      "Resuming model from: models/Transfer_Brats2019_Flair_to_t2_freeze_all/best_dice_score_0_191-19, next epoch: 192\n"
     ]
    }
   ],
   "source": [
    "for modality in full_network['modalities']:\n",
    "    if modality == 'flair':\n",
    "        continue\n",
    "    transfer_from_flair[modality]['checkpoint'] = glob.glob(MODELS_PATH + transfer_from_flair[modality]['path'] + '/' + checkpoint_basename + str(transfer_from_flair[modality]['epoch']) + '*.index')[0].replace('.index', '')\n",
    "\n",
    "\n",
    "for modality in [m for m in full_network['modalities'] if m != 'flair']:\n",
    "    transfer_from_flair[modality]['checkpoint'] = glob.glob(MODELS_PATH + transfer_from_flair[modality]['path'] + '/' + checkpoint_basename + str(transfer_from_flair[modality]['epoch']) + '*.index')[0].replace('.index', '')\n",
    "    transfer_from_flair[modality]['model'] = DeepMRI(batch_size=64, size=model_input_size, mri_channels=len(transfer_from_flair[modality]['modalities']), output_labels=output_labels, model_name=transfer_from_flair[modality]['path'])\n",
    "    transfer_from_flair[modality]['model'].build_model(load_model=transfer_from_flair[modality]['checkpoint'], seed=1234567890, arch=seganio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    for m, modality in enumerate([m for m in full_network['modalities'] if m != 'flair']):\n",
    "        predictions.append(transfer_from_flair[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    \n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'maximum').astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    \n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2019_majority_voting_performances_transfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, this is going to work only if the output is binary and single-label\n"
     ]
    }
   ],
   "source": [
    "eval_logger = pd.DataFrame()\n",
    "print(\"Warning, this is going to work only if the output is binary and single-label\")\n",
    "for i, row in enumerate(test_data):\n",
    "    predictions = list()\n",
    "    weights = list()\n",
    "    for m, modality in enumerate([m for m in full_network['modalities'] if m != 'flair']):\n",
    "        predictions.append(transfer_from_flair[modality]['model'].generator(row['mri'][:,:,:,m][..., tf.newaxis]).numpy())\n",
    "        weights.append(transfer_from_flair[modality]['weight'])\n",
    "        \n",
    "    predictions = np.stack(predictions, axis=1)\n",
    "    weights = np.asarray(weights)\n",
    "    weights = weights/np.sum(weights)\n",
    "    \n",
    "    # Proposals has to be \"one hot\" for the last channel        \n",
    "    proposals = np.stack([1.-predictions[...,0], predictions[...,0]], axis=-1)\n",
    "    weights = np.tile(weights[:, None, None, None], [1, proposals.shape[2], proposals.shape[3], 2])\n",
    "    mv_predictions = np.stack([negtools.compute_majority_voting(mri_slice, 'maximum', weights=weights).astype(np.float32) for mri_slice in proposals], axis=0)[..., 1, np.newaxis]\n",
    "    \n",
    "    metrics = full_network['model'].compute_metrics(row['seg'], mv_predictions)\n",
    "    eval_logger = full_network['model'].log_step(eval_logger, row, None, metrics)\n",
    "eval_logger['loss_g'] = 0\n",
    "eval_logger['loss_d'] = 0\n",
    "mv_results_single  = full_network['model'].log_epoch(eval_logger, 'testing', 0, None)\n",
    "mv_results_single.to_csv('results/brats2019_weighted_majority_voting_performances_transfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
